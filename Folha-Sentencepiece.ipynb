{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Lula diz que está 'lascado', mas que ainda tem...</td>\n",
       "      <td>Com a possibilidade de uma condenação impedir ...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>poder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>'Decidi ser escrava das mulheres que sofrem', ...</td>\n",
       "      <td>Para Oumou Sangaré, cantora e ativista malines...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>ilustrada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Três reportagens da Folha ganham Prêmio Petrob...</td>\n",
       "      <td>Três reportagens da Folha foram vencedoras do ...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>poder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Filme 'Star Wars: Os Últimos Jedi' ganha trail...</td>\n",
       "      <td>A Disney divulgou na noite desta segunda-feira...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>ilustrada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CBSS inicia acordos com fintechs e quer 30% do...</td>\n",
       "      <td>O CBSS, banco da holding Elopar dos sócios Bra...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2017/10/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Lula diz que está 'lascado', mas que ainda tem...   \n",
       "1  'Decidi ser escrava das mulheres que sofrem', ...   \n",
       "2  Três reportagens da Folha ganham Prêmio Petrob...   \n",
       "3  Filme 'Star Wars: Os Últimos Jedi' ganha trail...   \n",
       "4  CBSS inicia acordos com fintechs e quer 30% do...   \n",
       "\n",
       "                                                text        date   category  \\\n",
       "0  Com a possibilidade de uma condenação impedir ...  2017-09-10      poder   \n",
       "1  Para Oumou Sangaré, cantora e ativista malines...  2017-09-10  ilustrada   \n",
       "2  Três reportagens da Folha foram vencedoras do ...  2017-09-10      poder   \n",
       "3  A Disney divulgou na noite desta segunda-feira...  2017-09-10  ilustrada   \n",
       "4  O CBSS, banco da holding Elopar dos sócios Bra...  2017-09-10    mercado   \n",
       "\n",
       "  subcategory                                               link  \n",
       "0         NaN  http://www1.folha.uol.com.br/poder/2017/10/192...  \n",
       "1         NaN  http://www1.folha.uol.com.br/ilustrada/2017/10...  \n",
       "2         NaN  http://www1.folha.uol.com.br/poder/2017/10/192...  \n",
       "3         NaN  http://www1.folha.uol.com.br/ilustrada/2017/10...  \n",
       "4         NaN  http://www1.folha.uol.com.br/mercado/2017/10/1...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#articles.csv available  at https://www.kaggle.com/marlesson/news-of-the-site-folhauol\n",
    "articles = pd.read_csv('articles.csv')\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167053, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lula diz que está 'lascado', mas que ainda tem força como cabo eleitoral\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.title[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentencepiece (Words vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 494 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.85\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titles = articles.title.apply(lambda x: re.sub('[\\t]', '', x)).str.cat(sep=' ')\n",
    "titles = articles.title.apply(lambda x: re.sub('[\\t]', '', '<s> '+ x + '</s>')).str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11725850"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_file = open('titles.txt', 'w+')\n",
    "titles_file.write(titles)\n",
    "titles_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train('--input=titles.txt --model_prefix=m --user_defined_symbols=<s>,</s> --vocab_size=8000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('m.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', '<s>', '▁Brasil', '▁e', 'con', 'ômi', 'a', '</s>']\n",
      "[3, 1, 37, 7, 685, 4031, 14, 2]\n",
      "Brasil econômia\n",
      "se, Russomanno confirmadoa\n"
     ]
    }
   ],
   "source": [
    "# text => id\n",
    "print(sp.encode_as_pieces(' <s> Brasil econômia</s>'))\n",
    "print(sp.encode_as_ids('<s> Brasil econômia</s>'))\n",
    "\n",
    "# id => text\n",
    "print(sp.decode_pieces(['▁Brasil', '▁e', 'con', 'ômi', 'a']))\n",
    "print(sp.decode_ids([34, 6, 714, 5195, 14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.id_to_piece(1) == '<s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "▁TV\n",
      "161\n",
      "0\n",
      "<unk> False\n",
      "<s> False\n",
      "</s> False\n"
     ]
    }
   ],
   "source": [
    "print(sp.get_piece_size())\n",
    "\n",
    "# id <=> piece conversion\n",
    "print(sp.id_to_piece(209))\n",
    "print(sp.piece_to_id('í'))\n",
    "\n",
    "print(sp.piece_to_id('__MUST_BE_UNKNOWN__'))\n",
    "\n",
    "# <unk>, <s>, </s> are defined by default. Their ids are (0, 1, 2)\n",
    "# <s> and </s> are defined as 'control' symbol.\n",
    "for id in range(3):\n",
    "  print(sp.id_to_piece(id), sp.is_control(id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3074017"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_as_id = []\n",
    "for title in titles.split(sep='</s>')[:-1]:\n",
    "    titles_as_id+=sp.encode_as_ids(title)\n",
    "    titles_as_id.append(sp.piece_to_id('</s>'))\n",
    "len(titles_as_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a<s> casa ' quein no encerrações sobre paras como que Hillary temceri Figueirense Marta</s>\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.decode_ids([8, 1, 132, 23, 20, 146, 18, 1569, 120, 40, 16, 5, 72, 20, 289, 45, 545, 68, 6467, 678, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.id_to_piece(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 1,\n",
       " 160,\n",
       " 22,\n",
       " 20,\n",
       " 158,\n",
       " 23,\n",
       " 733,\n",
       " 63,\n",
       " 30,\n",
       " 13,\n",
       " 6,\n",
       " 78,\n",
       " 20,\n",
       " 319,\n",
       " 45,\n",
       " 624,\n",
       " 72,\n",
       " 3,\n",
       " 63,\n",
       " 200,\n",
       " 752,\n",
       " 2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.encode_as_ids(\"<s> Lula diz que está 'lascado', mas que ainda tem força como cabo eleitoral</s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_dataset = tf.data.Dataset.from_tensor_slices(titles_as_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 25\n",
    "sequences = titles_dataset.batch(seq_len, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sentence):\n",
    "    input_text = sentence[:-1]\n",
    "    target_text = sentence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_target = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Lula diz que está 'lascado', mas que ainda tem força como cabo eleitoral</s> \n",
      "<s> Lula diz que está 'lascado', mas que ainda tem força como cabo eleitoral</s> <s>\n",
      "'Decidi ser escrava das mulheres que sofrem', diz cantora Oumou Sangaré</s>\n",
      "Decidi ser escrava das mulheres que sofrem', diz cantora Oumou Sangaré</s> \n"
     ]
    }
   ],
   "source": [
    "for input_text, target_text in data_input_target.take(2):\n",
    "    print(sp.decode_ids(input_text.numpy().tolist()))\n",
    "    print(sp.decode_ids(target_text.numpy().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_input_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d8a8147fc9d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mBUFFER_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_input_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_input_target' is not defined"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "batches = data_input_target.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = sp.get_piece_size()\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           2048000   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 8000)          8200000   \n",
      "=================================================================\n",
      "Total params: 14,186,304\n",
      "Trainable params: 14,186,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_latest\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1921 steps\n",
      "Epoch 1/3\n",
      "1921/1921 [==============================] - 825s 430ms/step - loss: 2.9921\n",
      "Epoch 2/3\n",
      "1921/1921 [==============================] - 826s 430ms/step - loss: 2.8840\n",
      "Epoch 3/3\n",
      "1921/1921 [==============================] - 827s 430ms/step - loss: 2.7978\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "history = model.fit(batches, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (1, None, 256)            2048000   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (1, None, 8000)           8200000   \n",
      "=================================================================\n",
      "Total params: 14,186,304\n",
      "Trainable params: 14,186,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    start_str_ids = sp.encode_as_ids(start_string)\n",
    "    input_eval = start_str_ids\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated_id = []\n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    temperature = 0.3\n",
    "    model.reset_states()\n",
    "    while len(text_generated_id)==0 or (text_generated_id[-1] != 2 and len(text_generated_id)<40):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated_id.append(int(predicted_id))\n",
    "\n",
    "    #return start_string + ' ' +(sp.decode_ids(text_generated_id))\n",
    "    return sp.decode_ids(start_str_ids+text_generated_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em pronunciamento na ONU, Dilma diz estar 'indignado'</s>\n",
      "Em pronunciamento na ONU, Hollande diz que sanções dos EUA são políticas</s>\n",
      "Em pronunciamento na ONU, Hollande diz que vai 'seme'</s>\n",
      "Em pronunciamento na ONU, Dilma defende diplomacia</s>\n",
      "Em pronunciamento na ONU, Hollande diz que será candidato a presidente do São Paulo</s>\n",
      "Em pronunciamento na ONU, Hollande diz que sanções foram ameaçados</s>\n",
      "Em pronunciamento na ONU, Hollande diz que pau de selfie</s>\n",
      "Em pronunciamento na ONU, Dilma veta correção do 'Sattoday Night Live'</s>\n",
      "Em pronunciamento na ONU, Dilma veta correção de cálculos de benefícios</s>\n",
      "Em pronunciamento na ONU, Dilma cita Dilma Rousseff</s>\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(generate_text(model, \"Em pronunciamento na ONU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brasil passa a valer pelos EUA</s>\n",
      "Brasil passa a valer pelo menos até novembro</s>\n",
      "Brasil passa a valer pela 2a vez seguida</s>\n",
      "Brasil passa a valer pelo país</s>\n",
      "Brasil passa EUA por dificuldades financeiras, diz ex-presidente</s>\n",
      "Brasil passa a valer pela 2a vez seguida</s>\n",
      "Brasil passa a valer pelo menos R$ 2,7 bi</s>\n",
      "Brasil passa a valer pelo menos R$ 2,7 bi</s>\n",
      "Brasil passa a valer pelo menos bloqueio de turistas</s>\n",
      "Brasil passa a valer entrada de turistas</s>\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(generate_text(model, \"Brasil passa\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bolsonaro cobra responsabilidade por 'pau de selfie'</s>\n",
      "Bolsonaro cobra responsabilidade do governo</s>\n",
      "Bolsonaro! Nem meríram!</s>\n",
      "Bolsonaro diz que não é chamado de 'sexual'</s>\n",
      "Bolsonaro cobra responsabilidade de Dilma</s>\n",
      "Bolsonaro diz ter 'incisão' reuniões com investidores</s>\n",
      "Bolsonaro quer tratar de cadernosagem</s>\n",
      "Bolsonaro escolheu para visitar EUA</s>\n",
      "Bolsonaro! Nem meu!</s>\n",
      "Bolsonaro diz ter sido alvo de ataque a jornal</s>\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(generate_text(model, \"Bolsonaro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lula diz que Dilma terá que 'superar' desoneração da folha</s>\n",
      "Lula disse que Dilma age para investigações da Lava Jato</s>\n",
      "Lula diz que Marta terá 'novo normal'</s>\n",
      "Lula acusa Dilma de 'mentiroso'</s>\n",
      "Lula nega pedido de liberdade de executivos da empreiteira OAS</s>\n",
      "Lula acusa Dilma de agente</s>\n",
      "Lula diz que Dilma não quis ser uma bobagem</s>\n",
      "Lula afirma que Marta recebeu R$ 500 mi</s>\n",
      "Lula desabafa contra falta de luz</s>\n",
      "Lula diz que Dilma terá 'novo normal'</s>\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(generate_text(model, \"Lula\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Com cachê, Inter vence com facilidade e avança à semi do Aberto da Austrália</s>\n",
      "<s> Antes de ataque, grupo de Charlie Hebdo' chega às bancas em jornal</s>\n",
      "<s> Leitores comentam aumento salarial de até 12 horas após ônibus</s>\n",
      "<s>  ⁇ nibus é incendiado na zona leste de São Paulo</s>\n",
      "<s> O que as crianças estão chegando</s>\n",
      "<s> Após quase dois anos, Blatter diz que brasileiros estão garantidas na Copa</s>\n",
      "<s>  ⁇ nibus é incendiado na zona norte de São Paulo</s>\n",
      "<s>  ⁇ nibus é incendiado na zona leste de São Paulo</s>\n",
      "<s>  ⁇ ltimas Conversas entre índios e hip-hop</s>\n",
      "<s> Após temperaturas, nível do Cantareira volta a cair</s>\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(generate_text(model, \"<s>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retieving the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 256)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.layers[0].get_weights()[0]\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for id in range(sp.get_piece_size()):\n",
    "  vec = weights[id] # skip 0, it's padding.\n",
    "  out_m.write(sp.id_to_piece(id) + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
