{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Lula diz que está 'lascado', mas que ainda tem...</td>\n",
       "      <td>Com a possibilidade de uma condenação impedir ...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>poder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>'Decidi ser escrava das mulheres que sofrem', ...</td>\n",
       "      <td>Para Oumou Sangaré, cantora e ativista malines...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>ilustrada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Três reportagens da Folha ganham Prêmio Petrob...</td>\n",
       "      <td>Três reportagens da Folha foram vencedoras do ...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>poder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Filme 'Star Wars: Os Últimos Jedi' ganha trail...</td>\n",
       "      <td>A Disney divulgou na noite desta segunda-feira...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>ilustrada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CBSS inicia acordos com fintechs e quer 30% do...</td>\n",
       "      <td>O CBSS, banco da holding Elopar dos sócios Bra...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2017/10/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Lula diz que está 'lascado', mas que ainda tem...   \n",
       "1  'Decidi ser escrava das mulheres que sofrem', ...   \n",
       "2  Três reportagens da Folha ganham Prêmio Petrob...   \n",
       "3  Filme 'Star Wars: Os Últimos Jedi' ganha trail...   \n",
       "4  CBSS inicia acordos com fintechs e quer 30% do...   \n",
       "\n",
       "                                                text        date   category  \\\n",
       "0  Com a possibilidade de uma condenação impedir ...  2017-09-10      poder   \n",
       "1  Para Oumou Sangaré, cantora e ativista malines...  2017-09-10  ilustrada   \n",
       "2  Três reportagens da Folha foram vencedoras do ...  2017-09-10      poder   \n",
       "3  A Disney divulgou na noite desta segunda-feira...  2017-09-10  ilustrada   \n",
       "4  O CBSS, banco da holding Elopar dos sócios Bra...  2017-09-10    mercado   \n",
       "\n",
       "  subcategory                                               link  \n",
       "0         NaN  http://www1.folha.uol.com.br/poder/2017/10/192...  \n",
       "1         NaN  http://www1.folha.uol.com.br/ilustrada/2017/10...  \n",
       "2         NaN  http://www1.folha.uol.com.br/poder/2017/10/192...  \n",
       "3         NaN  http://www1.folha.uol.com.br/ilustrada/2017/10...  \n",
       "4         NaN  http://www1.folha.uol.com.br/mercado/2017/10/1...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "articles = pd.read_csv('articles.csv')\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167053, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lula diz que está 'lascado', mas que ainda tem força como cabo eleitoral\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.title[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentencepiece (Words vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 494 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.85\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titles = articles.title.apply(lambda x: re.sub('[\\t]', '', x)).str.cat(sep=' ')\n",
    "titles = articles.title.apply(lambda x: re.sub('[\\t]', '', '<s> '+ x + '</s>')).str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11725850"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_file = open('titles.txt', 'w+')\n",
    "titles_file.write(titles)\n",
    "titles_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train('--input=titles.txt --model_prefix=m --user_defined_symbols=<s>,</s> --vocab_size=10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('m.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', '<s>', '▁Brasil', '▁e', 'con', 'ômi', 'a', '</s>']\n",
      "[8, 1, 34, 6, 714, 5195, 14, 2]\n",
      "Brasil econômia\n",
      "Brasil econômia\n"
     ]
    }
   ],
   "source": [
    "# text => id\n",
    "print(sp.encode_as_pieces(' <s> Brasil econômia</s>'))\n",
    "print(sp.encode_as_ids('<s> Brasil econômia</s>'))\n",
    "\n",
    "# id => text\n",
    "print(sp.decode_pieces(['▁Brasil', '▁e', 'con', 'ômi', 'a']))\n",
    "print(sp.decode_ids([34, 6, 714, 5195, 14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.id_to_piece(1) == '<s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "í\n",
      "209\n",
      "0\n",
      "<unk> False\n",
      "<s> False\n",
      "</s> False\n"
     ]
    }
   ],
   "source": [
    "print(sp.get_piece_size())\n",
    "\n",
    "# id <=> piece conversion\n",
    "print(sp.id_to_piece(209))\n",
    "print(sp.piece_to_id('í'))\n",
    "\n",
    "print(sp.piece_to_id('__MUST_BE_UNKNOWN__'))\n",
    "\n",
    "# <unk>, <s>, </s> are defined by default. Their ids are (0, 1, 2)\n",
    "# <s> and </s> are defined as 'control' symbol.\n",
    "for id in range(3):\n",
    "  print(sp.id_to_piece(id), sp.is_control(id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955212"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_as_id = []\n",
    "for title in titles.split(sep='</s>')[:-1]:\n",
    "    titles_as_id+=sp.encode_as_ids(title)\n",
    "    titles_as_id.append(sp.piece_to_id('</s>'))\n",
    "len(titles_as_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> Lula diz que está 'lascado', mas que ainda tem força como cabo eleitoral</s>\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.decode_ids([8, 1, 132, 23, 20, 146, 18, 1569, 120, 40, 16, 5, 72, 20, 289, 45, 545, 68, 6467, 678, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.id_to_piece(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 1,\n",
       " 132,\n",
       " 23,\n",
       " 20,\n",
       " 146,\n",
       " 18,\n",
       " 1569,\n",
       " 120,\n",
       " 40,\n",
       " 16,\n",
       " 5,\n",
       " 72,\n",
       " 20,\n",
       " 289,\n",
       " 45,\n",
       " 545,\n",
       " 68,\n",
       " 6467,\n",
       " 678,\n",
       " 2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.encode_as_ids(\"<s> Lula diz que está 'lascado', mas que ainda tem força como cabo eleitoral</s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_dataset = tf.data.Dataset.from_tensor_slices(titles_as_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 30\n",
    "sequences = titles_dataset.batch(seq_len, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sentence):\n",
    "    input_text = sentence[:-1]\n",
    "    target_text = sentence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_target = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Lula diz que está 'lascado', mas que ainda tem força como cabo eleitoral</s> <s> 'Decidi ser\n",
      "<s> Lula diz que está 'lascado', mas que ainda tem força como cabo eleitoral</s> <s> 'Decidi ser \n",
      "escrava das mulheres que sofrem', diz cantora Oumou Sangaré</s> <s> Três reportagens da Folha ganham Prêmio\n",
      "das mulheres que sofrem', diz cantora Oumou Sangaré</s> <s> Três reportagens da Folha ganham Prêmio Petrobras\n"
     ]
    }
   ],
   "source": [
    "for input_text, target_text in data_input_target.take(2):\n",
    "    print(sp.decode_ids(input_text.numpy().tolist()))\n",
    "    print(sp.decode_ids(target_text.numpy().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 29), (64, 29)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "batches = data_input_target.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = sp.get_piece_size()\n",
    "\n",
    "embedding_dim = 512\n",
    "\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 512)           5120000   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          4724736   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 10000)         10250000  \n",
      "=================================================================\n",
      "Total params: 20,094,736\n",
      "Trainable params: 20,094,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_latest\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1539 steps\n",
      "Epoch 1/2\n",
      "1539/1539 [==============================] - 954s 620ms/step - loss: 3.2709\n",
      "Epoch 2/2\n",
      "1539/1539 [==============================] - 941s 612ms/step - loss: 3.0661\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "history = model.fit(batches, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (1, None, 512)            5120000   \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (1, None, 1024)           4724736   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 10000)          10250000  \n",
      "=================================================================\n",
      "Total params: 20,094,736\n",
      "Trainable params: 20,094,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    start_str_ids = sp.encode_as_ids(start_string)\n",
    "    input_eval = start_str_ids\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated_id = []\n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    temperature = 0.4\n",
    "    model.reset_states()\n",
    "    while len(text_generated_id)==0 or (text_generated_id[-1] != 2 and len(text_generated_id)<40):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated_id.append(int(predicted_id))\n",
    "\n",
    "    #return start_string + ' ' +(sp.decode_ids(text_generated_id))\n",
    "    return sp.decode_ids(start_str_ids+text_generated_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brasil passa por crise da Copa da Inglaterra</s>\n",
      "Brasil passa por crise e <s> Cúpula do PMDB diz que Marta é 'sultado' com atuação de Dilma</s>\n",
      "Brasil passa por crise, mas setores têm queda de 8,4% em 2014</s>\n",
      "Brasil passa por crise da Petrobras</s>\n",
      "Brasil passa por crise de até R$ 500 mil</s>\n",
      "Brasil passa por crises de petróleo e <s> Após ataque em Paris, 'Charlie Hebdo' lidera bilheterias em São Paulo</s>\n",
      "Brasil passa por crise na Venezuela</s>\n",
      "Brasil passa por crise da Petrobras</s>\n",
      "Brasil passa por crise da Vale</s>\n",
      "Brasil passa por crises no Brasil</s>\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(generate_text(model, \"Brasil passa por crise\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><s> Tottenham a violação das mulheres na capital paulista</s>\n",
      "<s><s> Editorial: Terrorismo</s>\n",
      "<s> Segunda temporada 2015 terá venda de ingressos para shows no Brasil</s>\n",
      "<s><s> Editorial: Disputa por direitos</s>\n",
      "<s><s> Crítica: 'Um Tiro', o Gregorio Duvivier, é preciso ter mais caro para a Olimpíada</s>\n",
      "<s><s> ONGs anunciam que negociação de paz na Ucrânia é inocente</s>\n",
      "<s><s> Editorial: As armas despedidas</s>\n",
      "<s> Em rede social, Dilma diz que não há espaço para o PMDB</s>\n",
      "<s><s> Após temperaturas, nível do Cantareira volta a cair</s>\n",
      "<s> Atentado suicida mata ao menos 20 na Nigéria</s>\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(generate_text(model, \"<s>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁descumpr'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.id_to_piece(5278)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.encode_as_ids(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
